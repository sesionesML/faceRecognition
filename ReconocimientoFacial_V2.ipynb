{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33fc7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de80142-1485-4b56-9875-2652b270dfaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagePaths= ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '59', '6', '63', '64', '65', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "dataPath = '/home/nvidia/Documents/RF/Reconocimiento Facial/Data' #Cambia a la ruta donde hayas almacenado Data\n",
    "imagePaths = sorted(os.listdir(dataPath))\n",
    "print('imagePaths=',imagePaths)\n",
    "\n",
    "#face_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "#face_recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Leyendo el modelo\n",
    "#face_recognizer.read('modeloEigenFace.xml')\n",
    "#face_recognizer.read('modeloFisherFace.xml')\n",
    "face_recognizer.read(dataPath + 'modeloLBPHFace.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "#cap = cv2.VideoCapture('Video.mp4')\n",
    "\n",
    "faceClassif = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Try connect\n",
    "cred =  open('cred.json',)\n",
    "credentials = json.load(cred)\n",
    "server = credentials['raiz']['server']\n",
    "database = credentials['raiz']['database']\n",
    "username = credentials['raiz']['username']\n",
    "passw = credentials['raiz']['password']\n",
    "driver= '/usr/lib/aarch64-linux-gnu/odbc/libtdsodbc.so'\n",
    "table_name = 'RegistroAsistencia'\n",
    "\n",
    "cnxn = pyodbc.connect(\n",
    "    driver = driver,\n",
    "    TDS_Version = '7.3', \n",
    "    server = server,\n",
    "    port = 1433,\n",
    "    DATABASE= 'AsistenciabSide',\n",
    "    uid = username,\n",
    "    pwd = passw)\n",
    "cursor = cnxn.cursor()\n",
    "registro = {'id_empleado': [], 'entrada':[]}\n",
    "\n",
    "while True:\n",
    "\tret,frame = cap.read()\n",
    "\tif ret == False: break\n",
    "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\tauxFrame = gray.copy()\n",
    "\n",
    "\tfaces = faceClassif.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "\tfor (x,y,w,h) in faces:\n",
    "\t\trostro = auxFrame[y:y+h,x:x+w]\n",
    "\t\trostro = cv2.resize(rostro,(150,150),interpolation= cv2.INTER_CUBIC)\n",
    "\t\tresult = face_recognizer.predict(rostro)\n",
    "\n",
    "\t\tcv2.putText(frame,'{}'.format(result),(x,y-5),1,1.3,(255,255,0),1,cv2.LINE_AA)\n",
    "\t\t'''\n",
    "\t\t# EigenFaces\n",
    "\t\tif result[1] < 5700:\n",
    "\t\t\tcv2.putText(frame,'{}'.format(imagePaths[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv2.LINE_AA)\n",
    "\t\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "\t\telse:\n",
    "\t\t\tcv2.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv2.LINE_AA)\n",
    "\t\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "\t\t\n",
    "\t\t# FisherFace\n",
    "\t\tif result[1] < 500:\n",
    "\t\t\tcv2.putText(frame,'{}'.format(imagePaths[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv2.LINE_AA)\n",
    "\t\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "\t\telse:\n",
    "\t\t\tcv2.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv2.LINE_AA)\n",
    "\t\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "\t\t'''\n",
    "\n",
    "\t\t# LBPHFace\n",
    "\t\tif result[1] < 70 :\n",
    "\t\t\tcv2.putText(frame,'{}'.format(imagePaths[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv2.LINE_AA)\n",
    "\t\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "\t\t\t\n",
    "\t\t\tlabel = imagePaths[result[0]]\n",
    "\t\t\tif label in registro['id_empleado']:\n",
    "\t\t\t\tpass\n",
    "\t\t\telse:\n",
    "\t\t\t\tregistro['id_empleado'].append(label)\n",
    "\t\t\t\tregistro['entrada'].append(datetime.datetime.now())\n",
    "\t\t\t\tdfasis = pd.DataFrame.from_dict(registro)\n",
    "\t\t\t\tdfasis['entrada'] = pd.to_datetime(dfasis['entrada'])\n",
    "\t\t\t\t# Insert Dataframe into SQL Server:\n",
    "\t\t\t\ttime.sleep(1)\n",
    "\t\t\t\tfor index, row in dfasis.iterrows():\n",
    "\t\t\t\t\tcursor.execute(\"INSERT INTO dbo.RegistroAsistencia (id_empleado,entrada) values(?,?)\", row.id_empleado, row.entrada)\n",
    "\t\t\t\tcnxn.commit()\n",
    "\t\t\t\ttime.sleep(1)\n",
    "\t\telse:\n",
    "\t\t\tcv2.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv2.LINE_AA)\n",
    "\t\t\tcv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2)\n",
    "\n",
    "\tcv2.imshow('frame',frame)\n",
    "\tk = cv2.waitKey(30)\n",
    "\tif  k & 0xff == ord('q'):\n",
    "\t\tcursor.close()\n",
    "\t\tbreak\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540c62c-0589-45dc-b2a1-ec1c6559b34a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
